

from pathlib import Path
import argparse
import sys
import time
import shutil
import cv2
import numpy as np

from ultralytics import YOLO
from ultralytics.utils import LOGGER

#å·¥ç¨‹æ ¹ç›®å½•ï¼ˆæŒ‰éœ€ä¿®æ”¹ï¼‰
ROOT = Path("/root/autodl-tmp/SWS3009Assg")


def is_video_source(src: str) -> bool:
    """åˆ¤æ–­æ˜¯å¦ä¸ºè§†é¢‘/æ‘„åƒå¤´æºï¼šæ–‡ä»¶æ‰©å±•åå¸¸è§è§†é¢‘æˆ–çº¯æ•°å­—ï¼ˆæ‘„åƒå¤´ï¼‰"""
    p = str(src).strip()
    if p.isdigit():
        return True
    ext = Path(p).suffix.lower()
    return ext in {".mp4", ".mov", ".avi", ".mkv", ".webm", ".m4v"}


def load_model(model_path: Path):
    """åŠ è½½ YOLO æ¨¡å‹ï¼ˆ.pt æˆ– .onnxï¼‰ã€‚è‹¥ .onnx é‡åˆ° ORT ä¸æ”¯æŒçš„é‡åŒ–ç®—å­ï¼ŒæŠ›å‡ºå‹å¥½æç¤ºã€‚"""
    try:
        model = YOLO(str(model_path))
        return model
    except Exception as e:
        msg = str(e)
        # é’ˆå¯¹ INT8 ONNX å¸¸è§æŠ¥é”™ï¼Œç»™å‡ºæŒ‡å¼•
        if "ConvInteger" in msg or "QLinearConv" in msg or "NOT_IMPLEMENTED" in msg.upper():
            LOGGER.error(
                f"\n[ERROR] ONNX Runtime ä¸æ”¯æŒè¯¥é‡åŒ–æ¨¡å‹çš„æŸäº›ç®—å­ï¼š\n{msg}\n"
                "ğŸ‘‰ è§£å†³æ–¹å¼ï¼š\n"
                "  A) ä½¿ç”¨ FP32 ONNX å†è¯•ï¼›æˆ–\n"
                "  B) åšâ€œå®‰å…¨é‡åŒ–â€ï¼ˆä»…é‡åŒ– MatMulï¼‰ï¼Œé¿å… ConvInteger/QLinearConvï¼›æˆ–\n"
                "  C) åœ¨æ”¯æŒ INT8 çš„ ORT build/å¹³å°ä¸Šè¿è¡Œï¼ˆoneDNN/DNNL INT8ï¼‰ã€‚\n"
            )
        raise


def ensure_outdir(project: Path, name: str) -> Path:
    out_dir = project / name
    out_dir.mkdir(parents=True, exist_ok=True)
    return out_dir


def write_mp4_init(out_path: Path, w: int, h: int, fps: float):
    # mp4v ç¼–ç å™¨åœ¨å¤§å¤šæ•°ç¯å¢ƒå¯ç”¨ï¼›å¦‚éœ€ H.264 å¯å°è¯• 'avc1' æˆ–åœ¨ ffmpeg è½¬ç 
    fourcc = cv2.VideoWriter_fourcc(*"mp4v")
    writer = cv2.VideoWriter(str(out_path), fourcc, max(1.0, fps), (w, h))
    if not writer.isOpened():
        raise RuntimeError(f"æ— æ³•æ‰“å¼€ MP4 å†™å…¥å™¨ï¼š{out_path}")
    return writer


def annotate_and_write_video(model: YOLO, source: str, out_dir: Path, imgsz=704, conf=0.35, device="cpu",
                             classes=None, save_sample=True, name="demo"):
    cap = cv2.VideoCapture(0 if source.strip().isdigit() else source)
    if not cap.isOpened():
        raise RuntimeError(f"æ— æ³•æ‰“å¼€è§†é¢‘/æ‘„åƒå¤´ï¼š{source}")

    w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH) or 1280)
    h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) or 720)
    fps = cap.get(cv2.CAP_PROP_FPS) or 25.0
    out_mp4 = out_dir / "output.mp4"
    writer = write_mp4_init(out_mp4, w, h, fps)

    LOGGER.info(f"[INFO] Writing MP4 to: {out_mp4}  ({w}x{h} @ {fps:.1f}fps)")
    t0 = time.time()
    n_frames, avg_fps, sample_saved = 0, 0.0, False

    while True:
        ok, frame = cap.read()
        if not ok:
            break

        # Ultralytics æ”¯æŒ numpy æ•°ç»„ç›´æ¥æ¨ç†
        results = model.predict(
            source=frame,
            imgsz=imgsz,
            conf=conf,
            device=device,
            classes=classes,
            verbose=False
        )

        # ç»˜åˆ¶å¯è§†åŒ–ï¼ˆæ¯å¸§åªæœ‰ä¸€ä¸ª resultï¼‰
        plotted = results[0].plot()  # np.ndarray, BGR
        writer.write(plotted)
        n_frames += 1

        # è®¡ç®—/æ˜¾ç¤ºé€Ÿåº¦
        avg_fps = 0.9 * avg_fps + 0.1 * (results[0].speed['inference'] and 1000.0 / results[0].speed['inference'] or 0.0)

        # å¦å­˜ä¸€ä¸ªç¤ºä¾‹å¸§ï¼ˆä¾›æŠ¥å‘Šæ’å›¾ï¼‰
        if save_sample and not sample_saved:
            sample_path = ROOT / "detection_sample.png"
            cv2.imwrite(str(sample_path), plotted)
            sample_saved = True

    cap.release()
    writer.release()
    LOGGER.info(f"[OK] Done. Frames: {n_frames}, time: {time.time() - t0:.1f}s, saved: {out_mp4}")
    return out_mp4


def annotate_images(model: YOLO, src: Path, out_dir: Path, imgsz=704, conf=0.35, device="cpu",
                    classes=None, stitch=False, fps=10):
    """
    å¤„ç†å•å›¾æˆ–æ–‡ä»¶å¤¹ï¼šä¿å­˜æ ‡æ³¨å›¾ç‰‡ï¼›å¯é€‰å°†å¤šå¼ å›¾åˆæˆä¸º MP4ï¼ˆstitch=Trueï¼‰
    """
    src = Path(src)
    img_paths = []
    if src.is_dir():
        for p in sorted(src.iterdir()):
            if p.suffix.lower() in {".jpg", ".jpeg", ".png", ".bmp", ".webp"}:
                img_paths.append(p)
    else:
        if src.suffix.lower() in {".jpg", ".jpeg", ".png", ".bmp", ".webp"}:
            img_paths = [src]

    if not img_paths:
        raise RuntimeError(f"åœ¨ {src} æœªæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶")

    out_imgs = []
    for p in img_paths:
        results = model.predict(
            source=str(p),
            imgsz=imgsz,
            conf=conf,
            device=device,
            classes=classes,
            save=False,
            verbose=False
        )
        plotted = results[0].plot()
        save_to = out_dir / p.name
        cv2.imwrite(str(save_to), plotted)
        out_imgs.append(save_to)

    # å¯é€‰ï¼šæŠŠå›¾ç‰‡åˆæˆä¸º MP4
    if stitch and out_imgs:
        sample = cv2.imread(str(out_imgs[0]))
        h, w = sample.shape[:2]
        out_mp4 = out_dir / "stitched.mp4"
        writer = write_mp4_init(out_mp4, w, h, fps)
        for p in out_imgs:
            im = cv2.imread(str(p))
            if im is None:
                continue
            if im.shape[1] != w or im.shape[0] != h:
                im = cv2.resize(im, (w, h))
            writer.write(im)
        writer.release()
        LOGGER.info(f"[OK] Stitched MP4 saved to: {out_mp4}")

    # å¦å­˜ä¸€å¼ ç¤ºä¾‹
    sample_png = ROOT / "detection_sample.png"
    if out_imgs:
        shutil.copyfile(out_imgs[0], sample_png)
    LOGGER.info(f"[OK] Images saved to: {out_dir}")
    return out_dir


def main():
    ap = argparse.ArgumentParser(description="Detect objects and save MP4/images (YOLO .pt/.onnx)")
    ap.add_argument("--model", type=str, required=True, help="æ¨¡å‹è·¯å¾„ï¼š.pt æˆ– .onnx")
    ap.add_argument("--source", type=str, required=True,
                    help="è¾“å…¥æºï¼šè§†é¢‘æ–‡ä»¶/æ‘„åƒå¤´ç¼–å·/å•å›¾/å›¾ç‰‡æ–‡ä»¶å¤¹")
    ap.add_argument("--imgsz", type=int, default=704, help="æ¨ç†åˆ†è¾¨ç‡")
    ap.add_argument("--conf", type=float, default=0.35, help="ç½®ä¿¡åº¦é˜ˆå€¼")
    ap.add_argument("--device", type=str, default="cpu", help="è®¾å¤‡ï¼š'cpu' æˆ– '0','1' ç­‰GPUç¼–å·")
    ap.add_argument("--name", type=str, default="demo_inference", help="è¾“å‡ºå­ç›®å½•å")
    ap.add_argument("--classes", type=str, default="", help="ä»…ä¿ç•™çš„ç±»åˆ«idï¼Œé€—å·åˆ†éš”ï¼Œå¦‚ '0,1,2'")
    ap.add_argument("--stitch", action="store_true", help="å½“è¾“å…¥ä¸ºå›¾ç‰‡æˆ–æ–‡ä»¶å¤¹æ—¶ï¼Œå°†å¤šå¼ å›¾åˆæˆä¸º MP4")
    args = ap.parse_args()

    model_path = Path(args.model)
    source = args.source
    device = args.device
    imgsz = args.imgsz
    conf = args.conf
    classes = [int(i) for i in args.classes.split(",")] if args.classes else None

    out_dir = ensure_outdir(ROOT / "runs" / "detect", args.name)

    # .onnx + deviceè‡ªåŠ¨ä¿®æ­£ï¼šonnx åœ¨å¤šæ•°ç¯å¢ƒä»…æ”¯æŒ cpu
    if model_path.suffix.lower() == ".onnx" and device != "cpu":
        LOGGER.warning("æ£€æµ‹åˆ° ONNX æ¨¡å‹ï¼Œå·²å¼ºåˆ¶åˆ‡æ¢ä¸º device='cpu' ä»¥ä¿è¯å…¼å®¹æ€§ã€‚")
        device = "cpu"

    # åŠ è½½æ¨¡å‹
    model = load_model(model_path)

    # åˆ†æ”¯ï¼šè§†é¢‘/æ‘„åƒå¤´ vs å›¾ç‰‡/ç›®å½•
    if is_video_source(source):
        annotate_and_write_video(
            model=model,
            source=source,
            out_dir=out_dir,
            imgsz=imgsz,
            conf=conf,
            device=device,
            classes=classes,
            save_sample=True,
            name=args.name,
        )
    else:
        annotate_images(
            model=model,
            src=Path(source),
            out_dir=out_dir,
            imgsz=imgsz,
            conf=conf,
            device=device,
            classes=classes,
            stitch=args.stitch,
            fps=10
        )


if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        LOGGER.error(f"[FATAL] {e}")
        sys.exit(1)
